---
title: "DATA622 Assignment 1"
author: "Norah Jones"
date: "March 22nd, 2021"
toc: true
format:
  html:
    html-math-method: katex
    code-tools: true
    self-contained: true
    toc_depth: 2
execute:
  warning: false
---

```{r}
#Load Packages
library(kableExtra)
library(arrow)
library(dplyr)
library(ggplot2)
library(reshape2)
library(patchwork)
library(lubridate)
library(DataExplorer)
library(skimr)
#install.packages("ROSE")
library(DescTools)
library(corrplot)
library(ggcorrplot)
library(caret)
library(rpart)
library(car)
library(rattle)
library(ROSE)

```

## Project

### **Deliverables**

Explore how to analyze and predict an outcome based on the data available. This will be an exploratory exercise, so feel free to show errors and warnings that raise during the analysis. Test the code with both datasets selected and compare the results.

### **Goals**

1.  Are the columns of your data correlated?

2.  Are there labels in your data? Did that impact your choice of algorithm?

3.  What are the pros and cons of each algorithm you selected?

4.  How your choice of algorithm relates to the datasets (was your choice of algorithm impacted by the datasets you chose)?

5.  Which result will you trust if you need to make a business decision?

6.  Do you think an analysis could be prone to errors when using too much data, or when using the least amount possible?

7.  How does the analysis between data sets compare?

## Large DataSet (End to End ML Analysis)

### Dataset Introduction

### Data Exploration & Plots

### Data Preparation

### Algorithm Selection

### Large DataSet Essay Summary

## Small DataSet (End to End ML Analysis)

### Dataset Introduction

### Data Exploration & Plots

```{r}


inputf <- read.csv("C:/Users/Banu/Documents/RScriptfiles/DATA 622/HOMEWORK1/Gitfiles/lending_club_loan_two.csv")

parquet = tempfile(fileext = ".parquet")
write_parquet(inputf, sink = parquet)

inputf1 = read_parquet(parquet)

#Glimpse variables
introduce(inputf1)
plot_intro(inputf1)
plot_missing(inputf1)
glimpse(inputf1)
unique(inputf1$loan_status)
skim(inputf1) %>% kable()
sapply(inputf1, function(x) sum(is.na(x))) %>% kable()






```

```{r}
# Select numeric columns only
 numeric_data<- inputf1[sapply(inputf1, is.numeric)]
M<- cor(numeric_data,use="complete.obs")
 # M %>% kable() %>%
 #  kable_styling()

ggcorrplot(M, type = "upper", outline.color = "white",
           ggtheme = theme_classic,
           #colors = c("#6D9EC1", "white", "#E46726"),
           lab = TRUE, show.legend = FALSE, tl.cex = 8, lab_size = 3)
           
# Calculate the correlation matrix
correlation_matrix <- cor(numeric_data, use="complete.obs")
kable(correlation_matrix)
corrplot(correlation_matrix, method="circle")



```

#### Review Distributions

```{r}
#Loan amt distribution
ggplot(data=inputf1, aes(loan_amnt))+geom_histogram(bins = 40,color="blue",fill="lightblue")

ggplot(inputf1, aes(x=grade, y=loan_amnt, fill=grade)) +
  stat_summary(fun.y="sum", geom="bar") +
  labs(y ="Total Loan Amount",title="Total loan amount based on loan grade")

ggplot(data=inputf1, aes(grade,int_rate,fill=grade))+geom_boxplot(outlier.color = "blue")+labs(title="Box plot of Interest rate")

plot_density(inputf1)


#Distribution of loan amount and purpose
Desc(inputf1$loan_amnt, main = "Loan amount distribution", plotit = TRUE)
Desc(inputf1$purpose, main = "Loan purposes", plotit = TRUE)

#Distribution by verification status
inputf1 %>% group_by(verification_status) %>% summarise(mean(loan_amnt), var(loan_amnt), mean(int_rate),mean(annual_inc))
ggplot(data = inputf1,aes(x = verification_status, y = loan_amnt))+geom_boxplot()

ggplot(data=inputf1,aes(loan_amnt, fill=grade))+
  geom_density(alpha=0.25) + 
  facet_grid(grade ~ .)

#Distribution of loan status and grade
table(inputf1$loan_status, inputf1$grade)
ggplot(inputf1, aes(x = int_rate))+ geom_histogram(aes(fill = grade)) + facet_wrap(~loan_status, ncol = 1)

#Distribution of loan status and term
table(inputf1$loan_status, inputf1$term)

index = createDataPartition(y = inputf1$loan_status, p = 0.90)[[1]]
loans.sample <- inputf1[-index,]
ggplot(loans.sample, aes(x = loan_amnt, y = int_rate)) + geom_point(aes(color = term))

```

### Data Preparation

```{r}

loan = inputf1 %>% mutate(loan_outcome = ifelse(loan_status %in% c('Charged Off' , 'Default') , 1, ifelse(loan_status == 'Fully Paid' , 0 , 'No info')))

barplot(table(loan$loan_outcome) , col = 'lightblue')

head(loan)

# Create the new dataset by filtering 0's and 1's in the loan_outcome and remove loan status.
loannew = loan %>% dplyr::select(-loan_status) %>% filter(loan_outcome %in% c(0 , 1))

dim(loannew)
unique(loannew$loan_outcome)

table(loannew$grade , factor(loannew$loan_outcome , c(0 , 1) , c('Fully Paid' , 'Default')))

ggplot(loannew , aes(x = grade , y = ..count.. , fill = factor(loan_outcome , c(1 , 0) , c('Default' , 'Fully Paid')))) + 
        geom_bar() + 
        theme(legend.title = element_blank())
```

### Algorithm Selection/Build Models

```{r}
index = createDataPartition(y = inputf1$loan_status, p = 0.8)[[1]]
loans.test <- inputf1[-index,]
loans.train <- inputf1[index,]
#loans.rpart.0 <- rpart(loan_status ~ ., data = loans.train)

loans.rpart.1 <- rpart(loan_status ~ . , data = loans.train, 
                      control=rpart.control(minsplit=10, minbucket = 3, cp=0.0006))

fancyRpartPlot(loans.rpart.1)

unique(loans.train$emp_title)

data_test_new <- loans.test                               # Duplicate test data set
data_test_new$emp_title[which(!(data_test_new$emp_title %in% unique(loans.train$emp_title)))] <- NA  # Replace new levels by NA
data_test_new$issue_d[which(!(data_test_new$issue_d %in% unique(loans.train$ issue_d)))] <- NA  # Replace new levels by NA
data_test_new$title[which(!(data_test_new$title %in% unique(loans.train$title)))] <- NA  # Replace new levels by NA
data_test_new$earliest_cr_line[which(!(data_test_new$earliest_cr_line %in% unique(loans.train$earliest_cr_line)))] <- NA  # Replace new levels by NA
head(data_test_new)
data_test_new$address[which(!(data_test_new$address %in% unique(loans.train$address)))] <- NA  # Replace new levels by NA
head(data_test_new)


predictions.1 <- (predict(loans.rpart.1, data_test_new , type = "class"))

confusionMatrix(predictions.1,)

levels(data_test_new$loan_status)

roc.curve(data_test_new$loan_status, predict(loans.rpart.1, data_test_new, type = "prob")[,1], plot = TRUE)


```

### Large DataSet Essay Summary

## Joint Comparison and Summary Essay
